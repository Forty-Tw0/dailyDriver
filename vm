#!/bin/bash

# looking-glass.io - Sharing Keyboard, Monitor, and Mouse via shared memory between host and guest?
# https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF

# hyper-v enlightenments make things faster for Window guests. hypervisor=off (-hypervisor) should still hide hyperv
# https://github.com/qemu/qemu/blob/master/docs/hyperv.txt

# I am spoofing SMBIOS HardwareIDs with $RANDOM for ban evasion and fingerprinting mitigation.
# You can find your host's SMBIOS IDs and pass those through instead. Use "dmidecode" to check
# Need to investigate further spoofing of VirtIO drivers and those hardware IDs

# ------------------------------------------------------- Kernel Config

# Outdated? https://wiki.installgentoo.com/index.php/PCI_passthrough#Step_0:_Compile_IOMMU_support_if_you_use_Gento
# Recompile kernel with these flags: https://wiki.installgentoo.com/index.php/PCI_passthrough

# Device Drivers --->
#  <M> VFIO Non-Privileged userspace driver framework  ---
#  [*]   VFIO No-IOMMU support  ----
#  <M>   VFIO support for PCI devices
#  [*]     VFIO PCI support for VGA devices
#  [*]     VFIO PCI extensions for Intel graphics (GVT-d)
#  <M>   Mediated device driver framework
#  <M>     VFIO driver for Mediated devices

#  [*] IOMMU Hardware Support --->
#        Generic IOMMU Pagetable Support  ----
#  [ ]   Export IOMMU internals in DebugFS
#  [ ]   IOMMU passthrough by default
#  [*]   AMD IOMMU support
#  <*>     AMD IOMMU Version 2 driver
#  [*]   Support for Intel IOMMU using DMA Remapping Devices
#  [*]     Support for Shared Virtual Memory with Intel IOMMU
#  [*]     Enable Intel DMA Remapping Devices by default
#  [*]   Support for Interrupt Remapping

# > Networking support > Networking options > Network packet filtering framework (Netfilter) > IP: Netfilter Configuration
#  <M>   iptables NAT support
#  <M>     MASQUERADE target support

# Boot kernel with: video=efifb:off,vesafb:off iommu=on intel_iommu=on amd_iommu=on pcie_acs_override=downstream

# ------------------------------------------------------- End Kernel Config

# Some GPUs might want their ROM to be passed in, I think Nvidea drivers do some checks for this. Maybe it isn't needed if the hypervisor is undetected.
# Nvidea drivers will intentionally refuse to load properly if they detect the hv_vendor_id to be the default of "Microsoft Hv". (code 43 driver error)
# Dump ROM for passthorugh, you might need to put your GPU in PCIeslot2 and have another GPU in slot1 while booted into a live CD for this to work!
#echo 1 > /sys/bus/pci/devices/$VGA_DEVICE/rom
#cat /sys/bus/pci/devices/$VGA_DEVICE/rom > /tmp/gpu.rom
#echo 0 > /sys/bus/pci/devices/$VGA_DEVICE/rom

# Configure PCI device IDs and driver for GPU. The entire IOMMU group must be unbound from the host the following command can dump those groupings.
# for iommu_group in $(find /sys/kernel/iommu_groups/ -maxdepth 1 -mindepth 1 -type d); do echo "IOMMU group $(basename "$iommu_group")"; for device in $(ls -1 "$iommu_group"/devices/); do echo -n $'\t'; lspci -nns "$device"; done; done
VGA_DRIVER=nouveau
VGA_DEVICE=0000:01:00.0
HDMI_AUDIO_DEVICE=0000:01:00.1

echo Refresh sudo timeout to avoid a race condition.
sudo -v

# Load VFIO-PCI driver so that /dev/vfio-pci is present
sudo modprobe vfio-pci

# Unbinds a device from the current drive and rebinds to the given driver.
changeDriver() {
	dev="$1"
	driver="$2"

	if [ -z $driver ] | [ -z $dev ];
	then
		return 1
	fi

	vendor=$(cat /sys/bus/pci/devices/$dev/vendor)
	device=$(cat /sys/bus/pci/devices/$dev/device)

	echo -n Unbinding $vendor:$device
	if [ -e /sys/bus/pci/devices/$dev/driver ]; then
		echo $dev | sudo tee /sys/bus/pci/devices/$dev/driver/unbind > /dev/null
		while [ -e /sys/bus/pci/devices/$dev/driver ]; do
			sleep 0.5
		done
	fi
	echo " OK!"

	echo -n Binding \'$driver\' to $vendor:$device
	echo $vendor $device | sudo tee /sys/bus/pci/drivers/$driver/new_id > /dev/null
	echo $dev | sudo tee /sys/bus/pci/drivers/$driver/bind > /dev/null
	echo " OK!"

	return 0
}

# Save current X config to restore it later
#savedXconfig=$(while read -r line ; do printf " %s" $line; done <<< `xrandr --current | grep " connected" | awk '{split($3,sizepos,"+"); print "--output "$1" --mode "sizepos[1]" --pos "sizepos[2]"x"sizepos[3]}'`)
#echo Saved X config as \'xrandr $savedXconfig\'
# Detatch from X, assuming the first monitor is the primary host monitor
#for monitor in `xrandr --listactivemonitors | awk 'NR>2 {print $4}'`; do xrandr --output $monitor --off; done

# If the host was booted with the GPU in use, unbind these
#echo Unbinding virtual consoles and efifb
#echo 0 | sudo tee /sys/class/vtconsole/vtcon0/bind
#echo 0 | sudo tee /sys/class/vtconsole/vtcon1/bind
#echo efi-framebuffer.0 | sudo tee /sys/bus/platform/drivers/efi-framebuffer/unbind

# Unbind GPU and its audio device.
echo Unbinding GPU
changeDriver $VGA_DEVICE vfio-pci
changeDriver $HDMI_AUDIO_DEVICE vfio-pci

### Networking
sudo modprobe vhost_net
sudo modprobe tun
sudo tunctl -t vmtap10
sudo ip link set dev vmtap10 address 42:42:42:42:42:42 # this MAC is only visible to the host
sudo ifconfig vmtap10 192.168.42.1 up # the VM can't see this IP either
echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward > /dev/null
sudo iptables -t nat -A POSTROUTING -o eno1 -j MASQUERADE # change this NIC name if needed
sudo iptables -A FORWARD -i vmtap10 -j ACCEPT
sudo iptables -A FORWARD -o vmtap10 -m state --state RELATED,ESTABLISHED -j ACCEPT

### Memory Allocation
RAM=24 # in gigabytes
#echo Mounting and dynamically allocating ${RAM}G of huge pages
# Try to drop and compact memory for contiguous blocks
#echo 3 | sudo tee /proc/sys/vm/drop_caches
#echo 1 | sudo tee /proc/sys/vm/compact_memory
#sudo mkdir -p /dev/hugepages
#sudo mountpoint -q /dev/hugepages && sudo mount -t hugetlbfs hugetlbfs /hugepages
# 1G pages are hard to get, so lets just use the standard 2M since they are better than the normal 4K pages
#sudo sysctl vm.nr_hugepages=$(($RAM/2*1024)) # number of 2M pages
# Huge pages are hard to allocate when RAM is fragmented
#-mem-path /dev/hugepages \

### CPU Affinity and Thread Priority
thread_count=7 # number of threads to give the VM, treat this as CPU cores with 1 thread each
# Spawn a background bash script to wait until VM threads have been created by Qemu
{
  # We can identify the important VM threads by using the sigmask of fffffffe7ffbf837 (is this reliable?)
  while [ $(ps -Leo sigmask,comm | grep "fffffffe7ffbf837 qemu" | wc -l) -lt $thread_count ]; do
    sleep 0.5
  done
  tnum=0
  for pid in `ps -Leo tid,sigmask,comm | grep "fffffffe7ffbf837 qemu" | awk '{print $1}'`; do
    # TODO: Make this topology aware (NUMA nodes) Intel hyperthreading and AMD SMT do this differently
    sudo taskset -pc $((tnum++)) $pid
    # Linux has priorities of 0-99 reserved for realtime scheduling and 100-139 for normal threads
    # Set the niceness to the max of -20 so that they have the highest priority of 0 (which 100 in userspace)
    sudo renice -n -20 -p $pid
    # We could give these threads the highest realtime priority with FIFO or RR, but that AGGRESSIVELY preempts the host
    # --fifo will wait until the thread releases control (if ever!), the thread will preempt others whenever it wants
    # --rr preempts like FIFO but the thread are required to yield after their time slice ends
    #sudo chrt --rr -p 99 $pid
  done
  echo VM threads pinned to CPU cores and prioritised
} &

### QEMU
sudo qemu-system-x86_64 -monitor stdio -vnc :1 -vga none -usb \
-machine type=q35,accel=kvm,kernel_irqchip=on -enable-kvm \
-rtc base=localtime -no-hpet \
-drive if=pflash,format=raw,file=/usr/share/edk2-ovmf/OVMF_CODE.fd \
-smbios type=0,vendor=$RANDOM,version=$RANDOM,date=$RANDOM,release=$RANDOM.$RANDOM,uefi=on \
-smbios type=1,manufacturer=$RANDOM,product=$RANDOM,version=$RANDOM,serial=$RANDOM,uuid=$(uuidgen),sku=$RANDOM,family=$RANDOM \
-smbios type=2,manufacturer=$RANDOM,product=$RANDOM,version=$RANDOM,serial=$RANDOM,asset=$RANDOM,location=$RANDOM \
-smbios type=3,manufacturer=$RANDOM,version=$RANDOM,serial=$RANDOM,asset=$RANDOM,sku=$RANDOM \
-smbios type=4,manufacturer=$RANDOM,sock_pfx=$RANDOM,version=$RANDOM,serial=$RANDOM,asset=$RANDOM,part=$RANDOM \
-smbios type=11,value=$RANDOM,value=$RANDOM,value=$RANDOM,value=$RANDOM \
-smbios type=17,manufacturer=$RANDOM,serial=$RANDOM,asset=$RANDOM,loc_pfx=$RANDOM,bank=$RANDOM,part=$RANDOM,speed=$RANDOM \
-cpu host,kvm=off,hypervisor=false,-hypervisor,hv-relaxed,hv-vapic,hv_spinlocks=0x1fff,hv-vpindex,hv-runtime,hv-time,hv-synic,hv-stimer,hv-tlbflush,hv-ipi,hv_vendor_id=$RANDOM \
-smp sockets=1,cores=$thread_count,threads=1 -m ${RAM}G \
-device ich9-intel-hda,bus=pcie.0,addr=0x1b -device hda-micro,audiodev=hda \
-audiodev pa,id=hda,server=unix:/run/user/$(id -u)/pulse/native,timer-period=1000,in.frequency=48000,out.frequency=48000 \
-device usb-audio,audiodev=usb,multi=on \
-audiodev pa,id=usb,server=unix:/run/user/$(id -u)/pulse/native,out.mixing-engine=off \
-device vfio-pci,host=$VGA_DEVICE,x-vga=on,multifunction=off,rombar=1,romfile=./gpu.rom \
-device usb-host,hostbus=3,hostport=3 \
-device usb-host,hostbus=3,hostport=4 \
-device usb-host,vendorid=0x046d,productid=0xc215 \
-device usb-host,vendorid=0x045e,productid=0x028e \
-drive file=/dev/disk/by-partuuid/385c0f02-3e9e-4c44-8613-92c40e35582a,format=raw,cache=none \
-serial tcp::4545,server,nowait \
-netdev tap,id=tap0,ifname=vmtap10,script=no,downscript=no,vhost=on \
-device virtio-net-pci,netdev=tap0,mac=$(openssl rand -hex 6 | sed 's/\(..\)/\1:/g; s/:$//') \
-netdev user,id=samba,smb=/samba -device virtio-net-pci,netdev=samba
#-device usb-host,vendorid=1133,productid=49685 \

# For windows network and storage drivers, load virtio into the cdrom
# Need to spoof these driver IDs later since they aid detection

### Cleanup

echo Refresh sudo timeout to avoid a race condition.
sudo -v

#echo Freeing huge pages
#sudo sysctl vm.nr_hugepages=0

echo Cleaning up network
sudo iptables -F
sudo iptables -t nat -F POSTROUTING
sudo ip link delete vmtap10
sudo tunctl -d vmtap10

echo Rebinding GPU
changeDriver $VGA_DEVICE $VGA_DRIVER
changeDriver $HDMI_AUDIO_DEVICE $AUDIO_DRIVER

#echo Rebinding efifb and virtual consoles # so that the host can use the GPU again
#echo efi-framebuffer.0 | sudo tee /sys/bus/platform/drivers/efi-framebuffer/bind
#echo 1 | sudo tee /sys/class/vtconsole/vtcon0/bind
#echo 1 | sudo tee /sys/class/vtconsole/vtcon1/bind

# re-enable monitors in X
xrandr $savedXconfig

echo Done
